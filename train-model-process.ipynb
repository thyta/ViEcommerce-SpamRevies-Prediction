{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install Keras-Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyvi.ViTokenizer import ViTokenizer #vietnamese tokenizer\n",
    "\n",
    "import re #regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "# from tensorflow.keras.models import Sequential \n",
    "\n",
    "from tensorflow.keras import layers, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from keras.preprocessing import text, sequence, tokenizer\n",
    "\n",
    "from tensorflow.keras.preprocessing import text, sequence \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Conv2D, MaxPool2D, Bidirectional, LSTM, GRU, concatenate, GlobalMaxPooling1D, GlobalAveragePooling1D, SpatialDropout1D, Reshape, Dropout, Concatenate\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "from keras.layers import Input, Dense, Embedding, Flatten, Conv2D, MaxPool2D, Bidirectional, LSTM, GRU, concatenate, GlobalMaxPooling1D, GlobalAveragePooling1D, SpatialDropout1D, Reshape, Flatten, Dropout, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_DATASET = os.path.join('dataset')\n",
    "\n",
    "PATH_TRAIN = os.path.join(DIR_DATASET, 'core-data\\\\train.csv')\n",
    "PATH_DEV = os.path.join(DIR_DATASET, 'core-data\\dev.csv')\n",
    "PATH_TEST = os.path.join(DIR_DATASET, 'core-data\\\\test.csv')\n",
    "\n",
    "EMBEDDING_PATH = os.path.join(DIR_DATASET, 'cc.vi.300.vec')\n",
    "TOKENIZER_PATH = os.path.join(DIR_DATASET, 'tokenizer.pickle')\n",
    "VISTOPWORDS_PATH = os.path.join(DIR_DATASET, \"vietnamese-stopwords.txt\")\n",
    "\n",
    "MODEL_DIR = 'model'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(PATH_TRAIN)\n",
    "\n",
    "data_dev = pd.read_csv(PATH_DEV)\n",
    "\n",
    "data_test = pd.read_csv(PATH_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VISTOPWORDS_PATH, \"r\", encoding=\"utf-8\") as ins:\n",
    "    stopwords = []\n",
    "    for line in ins:\n",
    "        dd = line.strip('\\n')\n",
    "        stopwords.append(dd)\n",
    "    stopwords = set(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv data\n",
    "data_train = pd.read_csv(PATH_TRAIN)\n",
    "data_dev = pd.read_csv(PATH_DEV)\n",
    "data_test = pd.read_csv(PATH_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['link', 'rating', 'comment', 'categories', 'category', 'product_name',\n",
       "       'description', 'num_sold', 'num_review', 'label', 'spam_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=data_train.drop(['link', 'rating', 'categories', 'category', 'product_name',\n",
    "       'description', 'num_sold', 'num_review', 'spam_label'], axis=1)\n",
    "data_dev=data_dev.drop(['link', 'rating', 'categories', 'category', 'product_name',\n",
    "       'description', 'num_sold', 'num_review', 'spam_label'], axis=1)\n",
    "data_test=data_test.drop(['link', 'rating', 'categories', 'category', 'product_name',\n",
    "       'description', 'num_sold', 'num_review', 'spam_label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sản phẩm đúng quảng cáo. giao hàng hơi chậm nh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mình nhận hàng ngày hôm qua, tiki giao hàng đú...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Máy giặt quá tốt, chỉ có 5 tr được cái máy giặ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chất liệu vải tốt mát nói chung là chất lượng ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tủ tốt giá tốt nhiều hơn so với các trung tâm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mọi người dưới 56kg nên mua sz S thoii nha. Fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>giao nhanh đóng hàng cẩn thận ăn ngon lắm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10 điểm. Giao hàng nhanh. Cầu hình cao màn hìn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bé nhà mình tiêu thụ loại này tốt!! Tuy nhiên ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ỏ Bến Tre mà vừa đặt hàng hôm qua nay nhận dc ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  label\n",
       "0  sản phẩm đúng quảng cáo. giao hàng hơi chậm nh...      0\n",
       "1  Mình nhận hàng ngày hôm qua, tiki giao hàng đú...      0\n",
       "2  Máy giặt quá tốt, chỉ có 5 tr được cái máy giặ...      0\n",
       "3  chất liệu vải tốt mát nói chung là chất lượng ...      0\n",
       "4   Tủ tốt giá tốt nhiều hơn so với các trung tâm...      0\n",
       "5  Mọi người dưới 56kg nên mua sz S thoii nha. Fo...      1\n",
       "6          giao nhanh đóng hàng cẩn thận ăn ngon lắm      0\n",
       "7  10 điểm. Giao hàng nhanh. Cầu hình cao màn hìn...      0\n",
       "8  Bé nhà mình tiêu thụ loại này tốt!! Tuy nhiên ...      0\n",
       "9  Ỏ Bến Tre mà vừa đặt hàng hôm qua nay nhận dc ...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train's duplicates:  8 \n",
      "dev's duplicates:  0 \n",
      "test's duplicates:  3\n"
     ]
    }
   ],
   "source": [
    "dup_train = data_train.duplicated().sum()\n",
    "dup_dev = data_dev.duplicated().sum()\n",
    "dup_test = data_test.duplicated().sum()\n",
    "\n",
    "print(\"train's duplicates: \", dup_train,\n",
    "    \"\\ndev's duplicates: \", dup_dev, \"\\ntest's duplicates: \", dup_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=data_train.drop_duplicates(keep='first')\n",
    "data_dev=data_dev.drop_duplicates(keep='first')\n",
    "data_test=data_test.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train's duplicates:  0 \n",
      "dev's duplicates:  0 \n",
      "test's duplicates:  0\n"
     ]
    }
   ],
   "source": [
    "dup_train = data_train.duplicated().sum()\n",
    "dup_dev = data_dev.duplicated().sum()\n",
    "dup_test = data_test.duplicated().sum()\n",
    "\n",
    "print(\"train's duplicates: \", dup_train,\n",
    "    \"\\ndev's duplicates: \", dup_dev, \"\\ntest's duplicates: \", dup_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filder stop word\n",
    "def filter_stop_words(train_sentences, stop_words):\n",
    "    new_sent = [word for word in train_sentences.split() if word not in stop_words]\n",
    "    train_sentences = ' '.join(new_sent)\n",
    "    return train_sentences\n",
    "\n",
    "# remove emoji\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "# declare func and adding some remove\n",
    "def preprocess(text, tokenized = True, lowercased = True):\n",
    "    text = ViTokenizer.tokenize(text) if tokenized else text\n",
    "    text = filter_stop_words(text, stopwords)\n",
    "    text = deEmojify(text)\n",
    "    text = text.lower() if lowercased else text\n",
    "\n",
    "    text = text.strip()\n",
    "    text = re.compile('<.*?>').sub('', text)\n",
    "    text = re.sub('\\s+', ' ', text) \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d',' ',text)\n",
    "    text = re.sub(r'\\s+',' ',text)\n",
    "    return text\n",
    "\n",
    "def pre_process_features(X, y, tokenized = True, lowercased = True):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = [preprocess(str(p), tokenized = tokenized, lowercased = lowercased) for p in list(X)]\n",
    "    for idx, ele in enumerate(X):\n",
    "        if not ele:\n",
    "            X = np.delete(X, idx)\n",
    "            y = np.delete(y, idx)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After preprocess:  [HN] Hiện tại bên mình vẫn đang cần tuyển vị trí C# developer (.NET framework, C# biết winforms (2-3 năm)) sẵn sàng làm thêm FE hoặc Python, Java nếu được giao. Lương thỏa thuận, có 13-15 tháng lương. Quan tâm ib lấy JD. \n",
      "\n",
      "Before preprocess:   hn hiện_tại tuyển vị_trí c developer net framework c winforms sẵn_sàng fe python java giao lương thỏa_thuận lương quan_tâm ib jd\n"
     ]
    }
   ],
   "source": [
    "text_01 = \"[HN] Hiện tại bên mình vẫn đang cần tuyển vị trí C# developer (.NET framework, C# biết winforms (2-3 năm)) sẵn sàng làm thêm FE hoặc Python, Java nếu được giao. Lương thỏa thuận, có 13-15 tháng lương. Quan tâm ib lấy JD.\"\n",
    "text_02 = preprocess(text_01)\n",
    "print(\"After preprocess: \", text_01, \"\\n\")\n",
    "print(\"Before preprocess: \", text_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sản phẩm đúng quảng cáo. giao hàng hơi chậm nh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mình nhận hàng ngày hôm qua, tiki giao hàng đú...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Máy giặt quá tốt, chỉ có 5 tr được cái máy giặ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chất liệu vải tốt mát nói chung là chất lượng ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tủ tốt giá tốt nhiều hơn so với các trung tâm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14301</th>\n",
       "      <td>dùng okee ko gây nóng máy nhưng chất của ốp om...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14302</th>\n",
       "      <td>Rất tốt, rất đáng tiền, nằm rất êm, lúc mới mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14303</th>\n",
       "      <td>giao đủ, đóng gói chắc chắn, giao hàng nhanh \\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14304</th>\n",
       "      <td>giao hỏa tốc rẻ và nhanh. Nhưng trước đó mình ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14305</th>\n",
       "      <td>Giao hàng nhanh, giá ổn, sản phẩm lắp sử dụng ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14298 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  label\n",
       "0      sản phẩm đúng quảng cáo. giao hàng hơi chậm nh...      0\n",
       "1      Mình nhận hàng ngày hôm qua, tiki giao hàng đú...      0\n",
       "2      Máy giặt quá tốt, chỉ có 5 tr được cái máy giặ...      0\n",
       "3      chất liệu vải tốt mát nói chung là chất lượng ...      0\n",
       "4       Tủ tốt giá tốt nhiều hơn so với các trung tâm...      0\n",
       "...                                                  ...    ...\n",
       "14301  dùng okee ko gây nóng máy nhưng chất của ốp om...      0\n",
       "14302  Rất tốt, rất đáng tiền, nằm rất êm, lúc mới mu...      0\n",
       "14303  giao đủ, đóng gói chắc chắn, giao hàng nhanh \\...      1\n",
       "14304  giao hỏa tốc rẻ và nhanh. Nhưng trước đó mình ...      0\n",
       "14305  Giao hàng nhanh, giá ổn, sản phẩm lắp sử dụng ...      0\n",
       "\n",
       "[14298 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slit data so that X_train is review and y_train is label\n",
    "X_train = data_train.iloc[:, 0:1]\n",
    "y_train = data_train.iloc[:, 1:2]\n",
    "\n",
    "X_dev = data_train.iloc[:, 0:1]\n",
    "y_dev = data_train.iloc[:, 1:2]\n",
    "\n",
    "X_test = data_train.iloc[:, 0:1]\n",
    "y_test = data_train.iloc[:, 1:2]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14301</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14302</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14303</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14304</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14305</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14298 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "...      ...\n",
       "14301      0\n",
       "14302      0\n",
       "14303      1\n",
       "14304      0\n",
       "14305      0\n",
       "\n",
       "[14298 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform X_train into narray (train_X) and simular\n",
    "train_X, train_y= pre_process_features(X_train['comment'], y_train['label'], tokenized=True, lowercased = True)\n",
    "dev_X, dev_y= pre_process_features(X_dev['comment'], y_dev['label'], tokenized=True, lowercased = True)\n",
    "test_X, test_y = pre_process_features(X_test['comment'], y_test['label'], tokenized=True, lowercased = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14271,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14271,)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECLARE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open(EMBEDDING_PATH, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(lower=False, filters='!\"#$%&()*+,-./:;<=>?@[\\]^`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TOKENIZER_PATH, 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_featues(X, y, tokenizer, is_one_hot_label=True, number_class1=2):\n",
    "#     X = tokenizer.texts_to_sequences(X)\n",
    "#     X = pad_sequences(X, maxlen=sequence_length)\n",
    "#     if is_one_hot_label: \n",
    "#         y = to_categorical(y, num_classes=number_class1)\n",
    "#     return X, y\n",
    "\n",
    "def make_featues(X, y, tokenizer, is_one_hot_label=False, number_class1=2): # my model just binary (non-spam or not spam)\n",
    "    X = tokenizer.texts_to_sequences(X)\n",
    "    X = pad_sequences(X, maxlen=sequence_length)\n",
    "    if is_one_hot_label: \n",
    "        y = to_categorical(y, num_classes=number_class1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "sequence_length = 100\n",
    "maxlen = 100\n",
    "\n",
    "embedding_dim = 300\n",
    "batch_size = 256\n",
    "epochs = 40\n",
    "drop = 0.5\n",
    "\n",
    "# filter_sizes = [2,3,5]\n",
    "# num_filters = 32\n",
    "\n",
    "filter_sizes = [2,3,5]\n",
    "num_filters = 32\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= vocabulary_size:\n",
    "        continue\n",
    "\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "sequence_length = 100\n",
    "\n",
    "embedding_dim = 300\n",
    "batch_size = 256\n",
    "epochs = 40\n",
    "drop = 0.5\n",
    "\n",
    "filter_sizes = [2,3,5]\n",
    "num_filters = 32\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= vocabulary_size:\n",
    "        continue\n",
    "\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_XX, train_yy = make_featues(train_X, train_y, tokenizer)\n",
    "dev_XX, dev_yy = make_featues(dev_X, dev_y, tokenizer)\n",
    "test_XX, test_yy = make_featues(test_X, test_y, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14271, 100)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0  268  141    3  710 6622   18\n",
      "  347   49  414  497   13   65   82 6623    4    7  711   37  119 2741\n",
      "  498  831]\n"
     ]
    }
   ],
   "source": [
    "print(train_XX[5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (14271, 100)\n",
      "<class 'numpy.ndarray'> (14271,)\n",
      "<class 'numpy.ndarray'> (14271, 100)\n",
      "<class 'numpy.ndarray'> (14271,)\n",
      "<class 'numpy.ndarray'> (14271, 100)\n",
      "<class 'numpy.ndarray'> (14271,)\n"
     ]
    }
   ],
   "source": [
    "print(type(train_XX), train_XX.shape)\n",
    "print(type(train_yy), train_yy.shape)\n",
    "print(type(dev_XX), dev_XX.shape)\n",
    "print(type(dev_yy), dev_yy.shape)\n",
    "print(type(test_XX), test_XX.shape)\n",
    "print(type(test_yy), test_yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14271, 100)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_XX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_max_pooling1d                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_max_pooling1d                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TextCNN\n",
    "# init layers\n",
    "textCNNModel = Sequential()\n",
    "\n",
    "# emmbed word vector\n",
    "textCNNModel.add(layers.Embedding(num_words, embedding_dim, input_length=sequence_length))\n",
    "\n",
    "# model\n",
    "textCNNModel.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "textCNNModel.add(layers.GlobalMaxPooling1D())\n",
    "textCNNModel.add(layers.Dense(256, activation='relu'))\n",
    "\n",
    "# Output layer for binary classification\n",
    "textCNNModel.add(layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "# Compile the model\n",
    "textCNNModel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "textCNNModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "56/56 - 13s - 224ms/step - accuracy: 0.7557 - loss: 0.5069 - val_accuracy: 0.8598 - val_loss: 0.3584\n",
      "Epoch 2/50\n",
      "56/56 - 11s - 192ms/step - accuracy: 0.8683 - loss: 0.3258 - val_accuracy: 0.9248 - val_loss: 0.2096\n",
      "Epoch 3/50\n",
      "56/56 - 12s - 206ms/step - accuracy: 0.9241 - loss: 0.1993 - val_accuracy: 0.9615 - val_loss: 0.1211\n",
      "Epoch 4/50\n",
      "56/56 - 11s - 198ms/step - accuracy: 0.9638 - loss: 0.1055 - val_accuracy: 0.9813 - val_loss: 0.0553\n",
      "Epoch 5/50\n",
      "56/56 - 11s - 196ms/step - accuracy: 0.9813 - loss: 0.0543 - val_accuracy: 0.9914 - val_loss: 0.0306\n",
      "Epoch 6/50\n",
      "56/56 - 11s - 199ms/step - accuracy: 0.9890 - loss: 0.0335 - val_accuracy: 0.9940 - val_loss: 0.0213\n",
      "Epoch 7/50\n",
      "56/56 - 12s - 216ms/step - accuracy: 0.9917 - loss: 0.0248 - val_accuracy: 0.9949 - val_loss: 0.0174\n",
      "Epoch 8/50\n",
      "56/56 - 11s - 199ms/step - accuracy: 0.9940 - loss: 0.0185 - val_accuracy: 0.9954 - val_loss: 0.0137\n",
      "Epoch 9/50\n",
      "56/56 - 11s - 200ms/step - accuracy: 0.9941 - loss: 0.0174 - val_accuracy: 0.9941 - val_loss: 0.0182\n",
      "Epoch 10/50\n",
      "56/56 - 12s - 210ms/step - accuracy: 0.9950 - loss: 0.0154 - val_accuracy: 0.9971 - val_loss: 0.0103\n",
      "Epoch 11/50\n",
      "56/56 - 11s - 198ms/step - accuracy: 0.9961 - loss: 0.0124 - val_accuracy: 0.9966 - val_loss: 0.0103\n",
      "Epoch 12/50\n",
      "56/56 - 11s - 197ms/step - accuracy: 0.9963 - loss: 0.0108 - val_accuracy: 0.9978 - val_loss: 0.0078\n",
      "Epoch 13/50\n",
      "56/56 - 11s - 200ms/step - accuracy: 0.9965 - loss: 0.0110 - val_accuracy: 0.9971 - val_loss: 0.0089\n",
      "Epoch 14/50\n",
      "56/56 - 11s - 199ms/step - accuracy: 0.9971 - loss: 0.0093 - val_accuracy: 0.9974 - val_loss: 0.0090\n",
      "Epoch 15/50\n",
      "56/56 - 11s - 198ms/step - accuracy: 0.9965 - loss: 0.0109 - val_accuracy: 0.9960 - val_loss: 0.0101\n",
      "Epoch 16/50\n",
      "56/56 - 11s - 198ms/step - accuracy: 0.9964 - loss: 0.0107 - val_accuracy: 0.9975 - val_loss: 0.0074\n",
      "Epoch 17/50\n",
      "56/56 - 11s - 198ms/step - accuracy: 0.9973 - loss: 0.0093 - val_accuracy: 0.9977 - val_loss: 0.0066\n",
      "Epoch 18/50\n",
      "56/56 - 11s - 195ms/step - accuracy: 0.9968 - loss: 0.0080 - val_accuracy: 0.9978 - val_loss: 0.0065\n",
      "Epoch 19/50\n",
      "56/56 - 11s - 200ms/step - accuracy: 0.9971 - loss: 0.0092 - val_accuracy: 0.9978 - val_loss: 0.0068\n",
      "Epoch 20/50\n",
      "56/56 - 11s - 198ms/step - accuracy: 0.9969 - loss: 0.0091 - val_accuracy: 0.9978 - val_loss: 0.0074\n",
      "Epoch 21/50\n",
      "56/56 - 12s - 206ms/step - accuracy: 0.9973 - loss: 0.0077 - val_accuracy: 0.9980 - val_loss: 0.0067\n",
      "Epoch 22/50\n",
      "56/56 - 12s - 206ms/step - accuracy: 0.9973 - loss: 0.0083 - val_accuracy: 0.9977 - val_loss: 0.0079\n",
      "Epoch 23/50\n",
      "56/56 - 11s - 196ms/step - accuracy: 0.9971 - loss: 0.0086 - val_accuracy: 0.9976 - val_loss: 0.0062\n",
      "Epoch 24/50\n",
      "56/56 - 11s - 197ms/step - accuracy: 0.9973 - loss: 0.0080 - val_accuracy: 0.9972 - val_loss: 0.0083\n",
      "Epoch 25/50\n",
      "56/56 - 11s - 199ms/step - accuracy: 0.9966 - loss: 0.0105 - val_accuracy: 0.9975 - val_loss: 0.0072\n",
      "Epoch 26/50\n",
      "56/56 - 11s - 196ms/step - accuracy: 0.9966 - loss: 0.0096 - val_accuracy: 0.9975 - val_loss: 0.0082\n",
      "Epoch 27/50\n",
      "56/56 - 11s - 196ms/step - accuracy: 0.9970 - loss: 0.0095 - val_accuracy: 0.9971 - val_loss: 0.0082\n",
      "Epoch 28/50\n",
      "56/56 - 11s - 199ms/step - accuracy: 0.9959 - loss: 0.0116 - val_accuracy: 0.9973 - val_loss: 0.0084\n",
      "Epoch 29/50\n",
      "56/56 - 11s - 195ms/step - accuracy: 0.9950 - loss: 0.0135 - val_accuracy: 0.9962 - val_loss: 0.0121\n",
      "Epoch 30/50\n",
      "56/56 - 11s - 197ms/step - accuracy: 0.9947 - loss: 0.0148 - val_accuracy: 0.9966 - val_loss: 0.0112\n",
      "Epoch 31/50\n",
      "56/56 - 11s - 198ms/step - accuracy: 0.9954 - loss: 0.0141 - val_accuracy: 0.9971 - val_loss: 0.0083\n",
      "Epoch 32/50\n",
      "56/56 - 11s - 195ms/step - accuracy: 0.9955 - loss: 0.0134 - val_accuracy: 0.9968 - val_loss: 0.0088\n",
      "Epoch 33/50\n",
      "56/56 - 11s - 196ms/step - accuracy: 0.9964 - loss: 0.0106 - val_accuracy: 0.9975 - val_loss: 0.0070\n",
      "Epoch 34/50\n",
      "56/56 - 11s - 201ms/step - accuracy: 0.9968 - loss: 0.0087 - val_accuracy: 0.9973 - val_loss: 0.0085\n",
      "Epoch 35/50\n",
      "56/56 - 11s - 199ms/step - accuracy: 0.9974 - loss: 0.0083 - val_accuracy: 0.9978 - val_loss: 0.0069\n",
      "Epoch 36/50\n",
      "56/56 - 11s - 196ms/step - accuracy: 0.9975 - loss: 0.0076 - val_accuracy: 0.9980 - val_loss: 0.0055\n",
      "Epoch 37/50\n",
      "56/56 - 11s - 199ms/step - accuracy: 0.9971 - loss: 0.0071 - val_accuracy: 0.9980 - val_loss: 0.0053\n",
      "Epoch 38/50\n",
      "56/56 - 11s - 196ms/step - accuracy: 0.9971 - loss: 0.0069 - val_accuracy: 0.9980 - val_loss: 0.0050\n",
      "Epoch 39/50\n",
      "56/56 - 11s - 198ms/step - accuracy: 0.9973 - loss: 0.0065 - val_accuracy: 0.9977 - val_loss: 0.0055\n",
      "Epoch 40/50\n",
      "56/56 - 11s - 199ms/step - accuracy: 0.9974 - loss: 0.0060 - val_accuracy: 0.9980 - val_loss: 0.0050\n",
      "Epoch 41/50\n",
      "56/56 - 11s - 196ms/step - accuracy: 0.9976 - loss: 0.0064 - val_accuracy: 0.9980 - val_loss: 0.0049\n",
      "Epoch 42/50\n",
      "56/56 - 11s - 197ms/step - accuracy: 0.9976 - loss: 0.0062 - val_accuracy: 0.9979 - val_loss: 0.0055\n",
      "Epoch 43/50\n",
      "56/56 - 11s - 201ms/step - accuracy: 0.9973 - loss: 0.0067 - val_accuracy: 0.9978 - val_loss: 0.0055\n",
      "Epoch 44/50\n",
      "56/56 - 11s - 196ms/step - accuracy: 0.9973 - loss: 0.0062 - val_accuracy: 0.9975 - val_loss: 0.0050\n",
      "Epoch 45/50\n",
      "56/56 - 11s - 195ms/step - accuracy: 0.9978 - loss: 0.0059 - val_accuracy: 0.9980 - val_loss: 0.0049\n",
      "Epoch 46/50\n",
      "56/56 - 11s - 198ms/step - accuracy: 0.9978 - loss: 0.0058 - val_accuracy: 0.9974 - val_loss: 0.0063\n",
      "Epoch 47/50\n",
      "56/56 - 11s - 198ms/step - accuracy: 0.9971 - loss: 0.0066 - val_accuracy: 0.9979 - val_loss: 0.0050\n",
      "Epoch 48/50\n",
      "56/56 - 11s - 196ms/step - accuracy: 0.9975 - loss: 0.0063 - val_accuracy: 0.9979 - val_loss: 0.0056\n",
      "Epoch 49/50\n",
      "56/56 - 11s - 197ms/step - accuracy: 0.9975 - loss: 0.0062 - val_accuracy: 0.9980 - val_loss: 0.0049\n",
      "Epoch 50/50\n",
      "56/56 - 12s - 209ms/step - accuracy: 0.9973 - loss: 0.0056 - val_accuracy: 0.9980 - val_loss: 0.0046\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1618ea53210>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for model accuracy\n",
    "textCNNModel.fit( train_XX, train_yy,\n",
    "    epochs=50,\n",
    "    verbose=2,\n",
    "    validation_data=(dev_XX, dev_yy),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 8ms/step - accuracy: 0.9986 - loss: 0.0036\n",
      "LOSS: 0.00463847117498517\n",
      "Accuracy 0.9980379939079285\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the TEST data\n",
    "loss, accuracy = textCNNModel.evaluate(test_XX, test_yy)\n",
    "print(f\"LOSS: {loss}\")\n",
    "print ('Accuracy '+ str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ spatial_dropout1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>) │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ spatial_dropout1d (\u001b[38;5;33mSpatialDropout1D\u001b[0m) │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LSTM\n",
    "# init layer\n",
    "lstmModel = Sequential()\n",
    "\n",
    "# emmbed word vectors\n",
    "lstmModel.add( layers.Embedding( num_words, embedding_dim, input_length=sequence_length ) )\n",
    "lstmModel.add( layers.SpatialDropout1D(0.2) )\n",
    "\n",
    "# lstmModel.add( layers.LSTM( 100, return_sequences=False, dropout=0.5, recurrent_dropout=0.5 ) )\n",
    "lstmModel.add( layers.LSTM( 100, return_sequences=False ) )\n",
    "lstmModel.add( layers.Dense( 512, activation=\"relu\" ) )\n",
    "\n",
    "# Output layer for binary classification\n",
    "lstmModel.add( layers.Dense( 1, activation=\"sigmoid\" ) )\n",
    "\n",
    "# Compile the model\n",
    "lstmModel.compile( optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "lstmModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "56/56 - 26s - 470ms/step - accuracy: 0.7800 - loss: 0.4932 - val_accuracy: 0.8599 - val_loss: 0.3359\n",
      "Epoch 2/50\n",
      "56/56 - 22s - 384ms/step - accuracy: 0.8629 - loss: 0.3265 - val_accuracy: 0.9074 - val_loss: 0.2506\n",
      "Epoch 3/50\n",
      "56/56 - 22s - 386ms/step - accuracy: 0.9060 - loss: 0.2433 - val_accuracy: 0.9287 - val_loss: 0.1989\n",
      "Epoch 4/50\n",
      "56/56 - 21s - 370ms/step - accuracy: 0.9292 - loss: 0.1848 - val_accuracy: 0.9536 - val_loss: 0.1290\n",
      "Epoch 5/50\n",
      "56/56 - 22s - 394ms/step - accuracy: 0.9474 - loss: 0.1413 - val_accuracy: 0.9603 - val_loss: 0.1091\n",
      "Epoch 6/50\n",
      "56/56 - 20s - 361ms/step - accuracy: 0.9566 - loss: 0.1172 - val_accuracy: 0.9676 - val_loss: 0.0864\n",
      "Epoch 7/50\n",
      "56/56 - 23s - 404ms/step - accuracy: 0.9621 - loss: 0.1003 - val_accuracy: 0.9701 - val_loss: 0.0868\n",
      "Epoch 8/50\n",
      "56/56 - 20s - 363ms/step - accuracy: 0.9654 - loss: 0.0892 - val_accuracy: 0.9690 - val_loss: 0.0750\n",
      "Epoch 9/50\n",
      "56/56 - 20s - 360ms/step - accuracy: 0.9702 - loss: 0.0769 - val_accuracy: 0.9777 - val_loss: 0.0611\n",
      "Epoch 10/50\n",
      "56/56 - 22s - 401ms/step - accuracy: 0.9742 - loss: 0.0663 - val_accuracy: 0.9769 - val_loss: 0.0590\n",
      "Epoch 11/50\n",
      "56/56 - 22s - 385ms/step - accuracy: 0.9739 - loss: 0.0637 - val_accuracy: 0.9809 - val_loss: 0.0548\n",
      "Epoch 12/50\n",
      "56/56 - 23s - 408ms/step - accuracy: 0.9774 - loss: 0.0609 - val_accuracy: 0.9840 - val_loss: 0.0462\n",
      "Epoch 13/50\n",
      "56/56 - 24s - 423ms/step - accuracy: 0.9795 - loss: 0.0553 - val_accuracy: 0.9841 - val_loss: 0.0450\n",
      "Epoch 14/50\n",
      "56/56 - 25s - 441ms/step - accuracy: 0.9811 - loss: 0.0504 - val_accuracy: 0.9854 - val_loss: 0.0382\n",
      "Epoch 15/50\n",
      "56/56 - 28s - 493ms/step - accuracy: 0.9834 - loss: 0.0450 - val_accuracy: 0.9875 - val_loss: 0.0358\n",
      "Epoch 16/50\n",
      "56/56 - 33s - 593ms/step - accuracy: 0.9849 - loss: 0.0410 - val_accuracy: 0.9871 - val_loss: 0.0348\n",
      "Epoch 17/50\n",
      "56/56 - 29s - 510ms/step - accuracy: 0.9854 - loss: 0.0371 - val_accuracy: 0.9885 - val_loss: 0.0315\n",
      "Epoch 18/50\n",
      "56/56 - 24s - 423ms/step - accuracy: 0.9854 - loss: 0.0407 - val_accuracy: 0.9879 - val_loss: 0.0364\n",
      "Epoch 19/50\n",
      "56/56 - 23s - 418ms/step - accuracy: 0.9840 - loss: 0.0426 - val_accuracy: 0.9876 - val_loss: 0.0343\n",
      "Epoch 20/50\n",
      "56/56 - 22s - 395ms/step - accuracy: 0.9855 - loss: 0.0371 - val_accuracy: 0.9910 - val_loss: 0.0279\n",
      "Epoch 21/50\n",
      "56/56 - 38s - 678ms/step - accuracy: 0.9891 - loss: 0.0309 - val_accuracy: 0.9911 - val_loss: 0.0254\n",
      "Epoch 22/50\n",
      "56/56 - 23s - 406ms/step - accuracy: 0.9879 - loss: 0.0343 - val_accuracy: 0.9911 - val_loss: 0.0263\n",
      "Epoch 23/50\n",
      "56/56 - 22s - 387ms/step - accuracy: 0.9888 - loss: 0.0291 - val_accuracy: 0.9923 - val_loss: 0.0224\n",
      "Epoch 24/50\n",
      "56/56 - 25s - 444ms/step - accuracy: 0.9891 - loss: 0.0280 - val_accuracy: 0.9903 - val_loss: 0.0265\n",
      "Epoch 25/50\n",
      "56/56 - 23s - 411ms/step - accuracy: 0.9894 - loss: 0.0264 - val_accuracy: 0.9932 - val_loss: 0.0196\n",
      "Epoch 26/50\n",
      "56/56 - 23s - 409ms/step - accuracy: 0.9900 - loss: 0.0244 - val_accuracy: 0.9923 - val_loss: 0.0211\n",
      "Epoch 27/50\n",
      "56/56 - 22s - 401ms/step - accuracy: 0.9906 - loss: 0.0255 - val_accuracy: 0.9938 - val_loss: 0.0214\n",
      "Epoch 28/50\n",
      "56/56 - 22s - 399ms/step - accuracy: 0.9878 - loss: 0.0357 - val_accuracy: 0.9902 - val_loss: 0.0286\n",
      "Epoch 29/50\n",
      "56/56 - 22s - 399ms/step - accuracy: 0.9886 - loss: 0.0325 - val_accuracy: 0.9935 - val_loss: 0.0192\n",
      "Epoch 30/50\n",
      "56/56 - 23s - 407ms/step - accuracy: 0.9912 - loss: 0.0236 - val_accuracy: 0.9941 - val_loss: 0.0186\n",
      "Epoch 31/50\n",
      "56/56 - 22s - 391ms/step - accuracy: 0.9918 - loss: 0.0207 - val_accuracy: 0.9949 - val_loss: 0.0163\n",
      "Epoch 32/50\n",
      "56/56 - 22s - 394ms/step - accuracy: 0.9929 - loss: 0.0198 - val_accuracy: 0.9946 - val_loss: 0.0157\n",
      "Epoch 33/50\n",
      "56/56 - 22s - 401ms/step - accuracy: 0.9929 - loss: 0.0190 - val_accuracy: 0.9944 - val_loss: 0.0167\n",
      "Epoch 34/50\n",
      "56/56 - 22s - 397ms/step - accuracy: 0.9925 - loss: 0.0193 - val_accuracy: 0.9950 - val_loss: 0.0147\n",
      "Epoch 35/50\n",
      "56/56 - 22s - 394ms/step - accuracy: 0.9927 - loss: 0.0197 - val_accuracy: 0.9950 - val_loss: 0.0149\n",
      "Epoch 36/50\n",
      "56/56 - 23s - 410ms/step - accuracy: 0.9931 - loss: 0.0184 - val_accuracy: 0.9953 - val_loss: 0.0149\n",
      "Epoch 37/50\n",
      "56/56 - 24s - 423ms/step - accuracy: 0.9940 - loss: 0.0169 - val_accuracy: 0.9959 - val_loss: 0.0123\n",
      "Epoch 38/50\n",
      "56/56 - 25s - 442ms/step - accuracy: 0.9939 - loss: 0.0158 - val_accuracy: 0.9961 - val_loss: 0.0125\n",
      "Epoch 39/50\n",
      "56/56 - 22s - 393ms/step - accuracy: 0.9943 - loss: 0.0167 - val_accuracy: 0.9951 - val_loss: 0.0139\n",
      "Epoch 40/50\n",
      "56/56 - 22s - 395ms/step - accuracy: 0.9937 - loss: 0.0173 - val_accuracy: 0.9954 - val_loss: 0.0125\n",
      "Epoch 41/50\n",
      "56/56 - 22s - 401ms/step - accuracy: 0.9943 - loss: 0.0158 - val_accuracy: 0.9961 - val_loss: 0.0123\n",
      "Epoch 42/50\n",
      "56/56 - 24s - 423ms/step - accuracy: 0.9927 - loss: 0.0193 - val_accuracy: 0.9954 - val_loss: 0.0130\n",
      "Epoch 43/50\n",
      "56/56 - 24s - 429ms/step - accuracy: 0.9932 - loss: 0.0184 - val_accuracy: 0.9955 - val_loss: 0.0138\n",
      "Epoch 44/50\n",
      "56/56 - 21s - 381ms/step - accuracy: 0.9927 - loss: 0.0207 - val_accuracy: 0.9952 - val_loss: 0.0133\n",
      "Epoch 45/50\n",
      "56/56 - 20s - 363ms/step - accuracy: 0.9927 - loss: 0.0179 - val_accuracy: 0.9957 - val_loss: 0.0128\n",
      "Epoch 46/50\n",
      "56/56 - 24s - 426ms/step - accuracy: 0.9936 - loss: 0.0201 - val_accuracy: 0.9961 - val_loss: 0.0114\n",
      "Epoch 47/50\n",
      "56/56 - 23s - 412ms/step - accuracy: 0.9943 - loss: 0.0146 - val_accuracy: 0.9962 - val_loss: 0.0111\n",
      "Epoch 48/50\n",
      "56/56 - 23s - 403ms/step - accuracy: 0.9950 - loss: 0.0144 - val_accuracy: 0.9968 - val_loss: 0.0103\n",
      "Epoch 49/50\n",
      "56/56 - 22s - 398ms/step - accuracy: 0.9960 - loss: 0.0121 - val_accuracy: 0.9971 - val_loss: 0.0086\n",
      "Epoch 50/50\n",
      "56/56 - 23s - 405ms/step - accuracy: 0.9960 - loss: 0.0102 - val_accuracy: 0.9970 - val_loss: 0.0089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1626a3ca610>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# utils.plot_model(lstmModel)\n",
    "lstmModel.fit( train_XX, train_yy,\n",
    "    epochs=50,\n",
    "    verbose=2,\n",
    "    validation_data=(test_XX, test_yy),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m446/446\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.9980 - loss: 0.0073\n",
      "LOSS: 0.008859078399837017\n",
      "Accuracy 0.9969869256019592\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the DEV data\n",
    "loss, accuracy = lstmModel.evaluate(test_XX, test_yy)\n",
    "print(f\"LOSS: {loss}\")\n",
    "print ('Accuracy '+ str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNs = os.path.join(MODEL_DIR, 'CNNs.keras')  # Use .keras extension\n",
    "\n",
    "# Save the model\n",
    "textCNNModel.save(CNNs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSTM = os.path.join(MODEL_DIR, 'LSTM.keras')  # Use .keras extension\n",
    "\n",
    "# Save the model\n",
    "lstmModel.save(LSTM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "USE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
      "padding string  [[  1  46  47  48   6   7   8   1  49   9  50  51  52  53  54  55  10   1\n",
      "   56  57  58  59   1  60   9  11  12  11  12  61  62   1  63  64  13  10\n",
      "   65  66  67  68  69  70  71  72  73  74  75  76  77  78  79  14  14  15\n",
      "   16  80  13  17  81  82  17  18  83  18  84  85  86  87  88  19  89  90\n",
      "   91  92  93  19  94  95  96  15  16  97  98  99 100 101 102 103 104 105\n",
      "  106 107 108 109 110 111 112 113 114 115]]\n",
      "predict score:  [[4.3783963e-08]]\n",
      "type: non-spam\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anhthy\\AppData\\Local\\Temp\\ipykernel_448\\1473920951.py:14: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  predicted_class = int(predictions > 0.5)  # assuming threshold of 0.5 for binary classification\n"
     ]
    }
   ],
   "source": [
    "input_string0 = \"Bỉm dùng thích, mua sale được giá tốt shop giao hàng nhanh sẽ ủng hộ tiếp\"\n",
    "input_string1 = \"Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu :)))) Xu\"\n",
    "input_string2 = \"Âjskskxjxndndjsjdjskssosojsjsisossksksjdhhsjsussusjsjsjsjs\"\n",
    "input_string4 = \"Có 4 Màu : Bạc - Vàng - Đen - Vàng Hồng ✚ Sản Phẩm : WR ✚ Tình trạng : mới ✚ Đồng hồ : nam nữ ✚ Kích thước: 36mm Dày : 5mm ✚ Chất liệu khung đồng hồ: thép không gỉ ✚ Chất liệu kính: Chống xước tốt. ✚ Loại dây đeo: thép không gỉ ✚ Chức năng hiển thị: Giờ, Phút, Giây, ngày, tháng ✚ Năng lượng: dùng pin ✚ Khả năng chống nước: chống nước sinh hoạt ✚ Bảo hành: 6 tháng ➥ Cam Kết ★★ 🚗 GIAO HÀNG & THANH TOÁN (COD) TẬN NƠI TRÊN TOÀN QUỐC. 👆 👆 BẢO HÀNH MÁY 6 THÁNG, PIN 12 THÁNG, 1 ĐỔI 1 TRONG VÒNG 7 NGÀY NẾU SẢN PHẨM LÀ LỖI CỦA NHÀ SẢN XUẤT 💲 KHÔNG BẢO HÀNH TRẦY XƯỚC BÊN NGOÀI #dongho #đồnghồnữ #sale #sangtrong #donghosapphire #donghothoitrang #donghonu #thoitrang #donghocaocap #donghogiare #donghodoi #đồnghồ #đồnghồnam #donghonam #chongnuoc\"\n",
    "\n",
    "tokenizer = text.Tokenizer(lower=False, filters='!\"#$%&()*+,-./:;<=>?@[\\]^`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts([input_string4])\n",
    "input_sequence = tokenizer.texts_to_sequences([input_string4])\n",
    "padded_input_sequence = pad_sequences(input_sequence, maxlen=maxlen) \n",
    "\n",
    "predictions = textCNNModel.predict(padded_input_sequence)\n",
    "\n",
    "# Assuming binary classification (0 or 1)\n",
    "predicted_class = int(predictions > 0.5)  # assuming threshold of 0.5 for binary classification\n",
    "\n",
    "print(\"padding string \", padded_input_sequence)\n",
    "print(\"predict score: \", predictions)\n",
    "\n",
    "if predicted_class > 0.5:\n",
    "    print(\"type: spam\")\n",
    "else:\n",
    "    print(\"type: non-spam\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_CRAWL= os.path.join(DIR_DATASET, 'core-data\\\\crawl.csv')\n",
    "data_crawl = pd.read_csv(PATH_CRAWL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Username</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Posted At</th>\n",
       "      <th>Product Categories</th>\n",
       "      <th>Review Text</th>\n",
       "      <th>Shop's response</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Page</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>h*****a</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-10-26 10:34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hàng giao đúng như trong mô tả, đóng gói đẹp, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ngocshina</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-04-26 16:29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Chưa dùng nên chưa biết hiệu quả. Giao hàng nh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t*****9</td>\n",
       "      <td>5</td>\n",
       "      <td>2022-02-16 21:19</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sản phẩm giao hàng rất nhanh, chất lượng tốt c...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hong_minh79</td>\n",
       "      <td>5</td>\n",
       "      <td>2023-02-14 22:21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Công dụng: giải rượu\\nMình đã mua lần 2. Uống ...</td>\n",
       "      <td>Rohto Mentholatum Việt Nam xin chào bạn, Rohto...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>trangtranggggg144</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-10-22 09:32</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hàng ok, đóng gói cẩm thận k bị vỡ. Chất lượng...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>hoangtuga</td>\n",
       "      <td>3</td>\n",
       "      <td>2023-05-17 21:40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Rohto Mentholatum Việt Nam xin chào bạn ạ Roht...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>tri_t_tien</td>\n",
       "      <td>2</td>\n",
       "      <td>2021-07-22 16:56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>minhminh070398</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-19 17:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Shop bảo có quà mà lại Không có quà tặng đi kèm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>tuantuoity_bn.84</td>\n",
       "      <td>1</td>\n",
       "      <td>2022-04-17 11:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cảm ơn bạn đã lựa chọn sản phẩm, shop rất mong...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>d*****9</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-08-06 16:39</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Username  Rating         Posted At  Product Categories  \\\n",
       "0              h*****a       5  2021-10-26 10:34                 NaN   \n",
       "1            ngocshina       5  2022-04-26 16:29                 NaN   \n",
       "2              t*****9       5  2022-02-16 21:19                 NaN   \n",
       "3          hong_minh79       5  2023-02-14 22:21                 NaN   \n",
       "4    trangtranggggg144       5  2021-10-22 09:32                 NaN   \n",
       "..                 ...     ...               ...                 ...   \n",
       "247          hoangtuga       3  2023-05-17 21:40                 NaN   \n",
       "248         tri_t_tien       2  2021-07-22 16:56                 NaN   \n",
       "249     minhminh070398       1  2021-05-19 17:20                 NaN   \n",
       "250   tuantuoity_bn.84       1  2022-04-17 11:04                 NaN   \n",
       "251            d*****9       1  2021-08-06 16:39                 NaN   \n",
       "\n",
       "                                           Review Text  \\\n",
       "0    Hàng giao đúng như trong mô tả, đóng gói đẹp, ...   \n",
       "1    Chưa dùng nên chưa biết hiệu quả. Giao hàng nh...   \n",
       "2    Sản phẩm giao hàng rất nhanh, chất lượng tốt c...   \n",
       "3    Công dụng: giải rượu\\nMình đã mua lần 2. Uống ...   \n",
       "4    Hàng ok, đóng gói cẩm thận k bị vỡ. Chất lượng...   \n",
       "..                                                 ...   \n",
       "247                                                NaN   \n",
       "248                                                NaN   \n",
       "249    Shop bảo có quà mà lại Không có quà tặng đi kèm   \n",
       "250                                                NaN   \n",
       "251                                                NaN   \n",
       "\n",
       "                                       Shop's response  Likes  Page  \n",
       "0                                                  NaN      0     1  \n",
       "1                                                  NaN      0     1  \n",
       "2                                                  NaN      0     1  \n",
       "3    Rohto Mentholatum Việt Nam xin chào bạn, Rohto...      0     1  \n",
       "4                                                  NaN      0     1  \n",
       "..                                                 ...    ...   ...  \n",
       "247  Rohto Mentholatum Việt Nam xin chào bạn ạ Roht...      0     1  \n",
       "248                                                NaN      0     1  \n",
       "249                                                NaN      0     1  \n",
       "250  Cảm ơn bạn đã lựa chọn sản phẩm, shop rất mong...      0     1  \n",
       "251                                                NaN      0     1  \n",
       "\n",
       "[252 rows x 8 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hàng giao đúng như trong mô tả, đóng gói đẹp, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chưa dùng nên chưa biết hiệu quả. Giao hàng nh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sản phẩm giao hàng rất nhanh, chất lượng tốt c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Công dụng: giải rượu\\nMình đã mua lần 2. Uống ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hàng ok, đóng gói cẩm thận k bị vỡ. Chất lượng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>Sản phẩm tốt, chất lượng tuy nhiên gói hàng sơ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>San pham su dung tot nen mua them cho gia dinh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>Đóng gói kĩ, giao hàng nhanh như mọi khi nhưng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>Hết tặng đèn thì gỡ xuống đi cho khách người t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>Shop bảo có quà mà lại Không có quà tặng đi kèm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>139 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Review Text\n",
       "0    Hàng giao đúng như trong mô tả, đóng gói đẹp, ...\n",
       "1    Chưa dùng nên chưa biết hiệu quả. Giao hàng nh...\n",
       "2    Sản phẩm giao hàng rất nhanh, chất lượng tốt c...\n",
       "3    Công dụng: giải rượu\\nMình đã mua lần 2. Uống ...\n",
       "4    Hàng ok, đóng gói cẩm thận k bị vỡ. Chất lượng...\n",
       "..                                                 ...\n",
       "242  Sản phẩm tốt, chất lượng tuy nhiên gói hàng sơ...\n",
       "243  San pham su dung tot nen mua them cho gia dinh...\n",
       "245  Đóng gói kĩ, giao hàng nhanh như mọi khi nhưng...\n",
       "246  Hết tặng đèn thì gỡ xuống đi cho khách người t...\n",
       "249    Shop bảo có quà mà lại Không có quà tặng đi kèm\n",
       "\n",
       "[139 rows x 1 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crawl_X = data_crawl.iloc[:, 4:5]\n",
    "# y_train = data_train.iloc[:, 1:2]\n",
    "crawl_X = crawl_X.dropna()\n",
    "crawl_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_comment_array(X, tokenized = True, lowercased = True):\n",
    "    X = np.array(X)\n",
    "    X = [preprocess(str(p), tokenized = tokenized, lowercased = lowercased) for p in list(X)]\n",
    "    for idx, ele in enumerate(X):\n",
    "        if not ele:\n",
    "            X = np.delete(X, idx)\n",
    "    return X\n",
    "\n",
    "def make_featues_comment_array(X, tokenizer, is_one_hot_label=False, number_class1=2):\n",
    "    X = tokenizer.texts_to_sequences(X)\n",
    "    X = pad_sequences(X, maxlen=sequence_length)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_crawl = pre_process_comment_array(crawl_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "XX_crawl = make_featues_comment_array(X_crawl, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 7]])"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XX_crawl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.99997157],\n",
       "       [0.9536588 ],\n",
       "       [0.99999994],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.99997157],\n",
       "       [0.9536588 ],\n",
       "       [0.99999994],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9999998 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9999998 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.99999994],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.99999994],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.99999994],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9999998 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9999998 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9999998 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ]], dtype=float32)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = lstmModel.predict(XX_crawl)\n",
    "\n",
    "predictions\n",
    "\n",
    "# # Add the predicted results to the DataFrame\n",
    "# data_crawl['predicted_result'] = [int(prediction > 0.5) for prediction in predictions]\n",
    "\n",
    "# data_crawl[['Review Text', 'predicted_result']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEST OLD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TEST_V1 = os.path.join(DIR_DATASET, 'core-data\\\\test_ver1.csv')\n",
    "data_test_v1 = pd.read_csv(PATH_TEST_V1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt1_X = data_test_v1.iloc[:, 4:5]\n",
    "# y_train = data_train.iloc[:, 1:2]\n",
    "dt1_X = dt1_X.dropna()\n",
    "\n",
    "X_dt1 = pre_process_comment_array(crawl_X)\n",
    "XX_dt1 = make_featues_comment_array(X_dt1, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9937124 ],\n",
       "       [0.757134  ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9937124 ],\n",
       "       [0.757134  ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9865527 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.999986  ],\n",
       "       [0.9536588 ],\n",
       "       [0.9865527 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.999986  ],\n",
       "       [0.9536588 ],\n",
       "       [0.9865527 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.999986  ],\n",
       "       [0.9536588 ],\n",
       "       [0.9865527 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.99370146],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.9536588 ],\n",
       "       [0.99999994]], dtype=float32)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = lstmModel.predict(XX_crawl)\n",
    "\n",
    "predictions\n",
    "\n",
    "# # Add the predicted results to the DataFrame\n",
    "# data_crawl['predicted_result'] = [int(prediction > 0.5) for prediction in predictions]\n",
    "\n",
    "# data_crawl[['Review Text', 'predicted_result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
