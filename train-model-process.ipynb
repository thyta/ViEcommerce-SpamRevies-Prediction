{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# !pip install Keras-Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyvi.ViTokenizer import ViTokenizer #vietnamese tokenizer\n",
    "\n",
    "import re #regular expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "\n",
    "# from tensorflow.keras.models import Sequential \n",
    "\n",
    "from tensorflow.keras import layers, Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# from keras.preprocessing import text, sequence, tokenizer\n",
    "\n",
    "from tensorflow.keras.preprocessing import text, sequence \n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Flatten, Conv2D, MaxPool2D, Bidirectional, LSTM, GRU, concatenate, GlobalMaxPooling1D, GlobalAveragePooling1D, SpatialDropout1D, Reshape, Dropout, Concatenate\n",
    "#from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "\n",
    "from keras.layers import Input, Dense, Embedding, Flatten, Conv2D, MaxPool2D, Bidirectional, LSTM, GRU, concatenate, GlobalMaxPooling1D, GlobalAveragePooling1D, SpatialDropout1D, Reshape, Flatten, Dropout, Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_DATASET = os.path.join('dataset')\n",
    "\n",
    "PATH_TRAIN = os.path.join(DIR_DATASET, 'core-data\\\\train.csv')\n",
    "PATH_DEV = os.path.join(DIR_DATASET, 'core-data\\dev.csv')\n",
    "PATH_TEST = os.path.join(DIR_DATASET, 'core-data\\\\test.csv')\n",
    "\n",
    "EMBEDDING_PATH = os.path.join(DIR_DATASET, 'cc.vi.300.vec')\n",
    "TOKENIZER_PATH = os.path.join(DIR_DATASET, 'tokenizer.pickle')\n",
    "VISTOPWORDS_PATH = os.path.join(DIR_DATASET, \"vietnamese-stopwords.txt\")\n",
    "\n",
    "MODEL_DIR = 'model'\n",
    "if not os.path.exists(MODEL_DIR):\n",
    "    os.makedirs(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(PATH_TRAIN)\n",
    "\n",
    "data_dev = pd.read_csv(PATH_DEV)\n",
    "\n",
    "data_test = pd.read_csv(PATH_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(VISTOPWORDS_PATH, \"r\", encoding=\"utf-8\") as ins:\n",
    "    stopwords = []\n",
    "    for line in ins:\n",
    "        dd = line.strip('\\n')\n",
    "        stopwords.append(dd)\n",
    "    stopwords = set(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv data\n",
    "data_train = pd.read_csv(PATH_TRAIN)\n",
    "data_dev = pd.read_csv(PATH_DEV)\n",
    "data_test = pd.read_csv(PATH_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['link', 'rating', 'comment', 'categories', 'category', 'product_name',\n",
       "       'description', 'num_sold', 'num_review', 'label', 'spam_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=data_train.drop(['link', 'rating', 'categories', 'category', 'product_name',\n",
    "       'description', 'num_sold', 'num_review', 'spam_label'], axis=1)\n",
    "data_dev=data_dev.drop(['link', 'rating', 'categories', 'category', 'product_name',\n",
    "       'description', 'num_sold', 'num_review', 'spam_label'], axis=1)\n",
    "data_test=data_test.drop(['link', 'rating', 'categories', 'category', 'product_name',\n",
    "       'description', 'num_sold', 'num_review', 'spam_label'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sản phẩm đúng quảng cáo. giao hàng hơi chậm nh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mình nhận hàng ngày hôm qua, tiki giao hàng đú...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Máy giặt quá tốt, chỉ có 5 tr được cái máy giặ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chất liệu vải tốt mát nói chung là chất lượng ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tủ tốt giá tốt nhiều hơn so với các trung tâm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mọi người dưới 56kg nên mua sz S thoii nha. Fo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>giao nhanh đóng hàng cẩn thận ăn ngon lắm</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10 điểm. Giao hàng nhanh. Cầu hình cao màn hìn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bé nhà mình tiêu thụ loại này tốt!! Tuy nhiên ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ỏ Bến Tre mà vừa đặt hàng hôm qua nay nhận dc ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment  label\n",
       "0  sản phẩm đúng quảng cáo. giao hàng hơi chậm nh...      0\n",
       "1  Mình nhận hàng ngày hôm qua, tiki giao hàng đú...      0\n",
       "2  Máy giặt quá tốt, chỉ có 5 tr được cái máy giặ...      0\n",
       "3  chất liệu vải tốt mát nói chung là chất lượng ...      0\n",
       "4   Tủ tốt giá tốt nhiều hơn so với các trung tâm...      0\n",
       "5  Mọi người dưới 56kg nên mua sz S thoii nha. Fo...      1\n",
       "6          giao nhanh đóng hàng cẩn thận ăn ngon lắm      0\n",
       "7  10 điểm. Giao hàng nhanh. Cầu hình cao màn hìn...      0\n",
       "8  Bé nhà mình tiêu thụ loại này tốt!! Tuy nhiên ...      0\n",
       "9  Ỏ Bến Tre mà vừa đặt hàng hôm qua nay nhận dc ...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train's duplicates:  8 \n",
      "dev's duplicates:  0 \n",
      "test's duplicates:  3\n"
     ]
    }
   ],
   "source": [
    "dup_train = data_train.duplicated().sum()\n",
    "dup_dev = data_dev.duplicated().sum()\n",
    "dup_test = data_test.duplicated().sum()\n",
    "\n",
    "print(\"train's duplicates: \", dup_train,\n",
    "    \"\\ndev's duplicates: \", dup_dev, \"\\ntest's duplicates: \", dup_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train=data_train.drop_duplicates(keep='first')\n",
    "data_dev=data_dev.drop_duplicates(keep='first')\n",
    "data_test=data_test.drop_duplicates(keep='first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train's duplicates:  0 \n",
      "dev's duplicates:  0 \n",
      "test's duplicates:  0\n"
     ]
    }
   ],
   "source": [
    "dup_train = data_train.duplicated().sum()\n",
    "dup_dev = data_dev.duplicated().sum()\n",
    "dup_test = data_test.duplicated().sum()\n",
    "\n",
    "print(\"train's duplicates: \", dup_train,\n",
    "    \"\\ndev's duplicates: \", dup_dev, \"\\ntest's duplicates: \", dup_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESS FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filder stop word\n",
    "def filter_stop_words(train_sentences, stop_words):\n",
    "    new_sent = [word for word in train_sentences.split() if word not in stop_words]\n",
    "    train_sentences = ' '.join(new_sent)\n",
    "    return train_sentences\n",
    "\n",
    "# remove emoji\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "# declare func and adding some remove\n",
    "def preprocess(text, tokenized = True, lowercased = True):\n",
    "    text = ViTokenizer.tokenize(text) if tokenized else text\n",
    "    text = filter_stop_words(text, stopwords)\n",
    "    text = deEmojify(text)\n",
    "    text = text.lower() if lowercased else text\n",
    "\n",
    "    text = text.strip()\n",
    "    text = re.compile('<.*?>').sub('', text)\n",
    "    text = re.sub('\\s+', ' ', text) \n",
    "    text = re.sub(r'\\[[0-9]*\\]',' ',text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d',' ',text)\n",
    "    text = re.sub(r'\\s+',' ',text)\n",
    "    return text\n",
    "\n",
    "def pre_process_features(X, y, tokenized = True, lowercased = True):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X = [preprocess(str(p), tokenized = tokenized, lowercased = lowercased) for p in list(X)]\n",
    "    for idx, ele in enumerate(X):\n",
    "        if not ele:\n",
    "            X = np.delete(X, idx)\n",
    "            y = np.delete(y, idx)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After preprocess:  [HN] Hiện tại bên mình vẫn đang cần tuyển vị trí C# developer (.NET framework, C# biết winforms (2-3 năm)) sẵn sàng làm thêm FE hoặc Python, Java nếu được giao. Lương thỏa thuận, có 13-15 tháng lương. Quan tâm ib lấy JD. \n",
      "\n",
      "Before preprocess:   hn hiện_tại tuyển vị_trí c developer net framework c winforms sẵn_sàng fe python java giao lương thỏa_thuận lương quan_tâm ib jd\n"
     ]
    }
   ],
   "source": [
    "text_01 = \"[HN] Hiện tại bên mình vẫn đang cần tuyển vị trí C# developer (.NET framework, C# biết winforms (2-3 năm)) sẵn sàng làm thêm FE hoặc Python, Java nếu được giao. Lương thỏa thuận, có 13-15 tháng lương. Quan tâm ib lấy JD.\"\n",
    "text_02 = preprocess(text_01)\n",
    "print(\"After preprocess: \", text_01, \"\\n\")\n",
    "print(\"Before preprocess: \", text_02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sản phẩm đúng quảng cáo. giao hàng hơi chậm nh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mình nhận hàng ngày hôm qua, tiki giao hàng đú...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Máy giặt quá tốt, chỉ có 5 tr được cái máy giặ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chất liệu vải tốt mát nói chung là chất lượng ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tủ tốt giá tốt nhiều hơn so với các trung tâm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14301</th>\n",
       "      <td>dùng okee ko gây nóng máy nhưng chất của ốp om...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14302</th>\n",
       "      <td>Rất tốt, rất đáng tiền, nằm rất êm, lúc mới mu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14303</th>\n",
       "      <td>giao đủ, đóng gói chắc chắn, giao hàng nhanh \\...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14304</th>\n",
       "      <td>giao hỏa tốc rẻ và nhanh. Nhưng trước đó mình ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14305</th>\n",
       "      <td>Giao hàng nhanh, giá ổn, sản phẩm lắp sử dụng ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14298 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 comment  label\n",
       "0      sản phẩm đúng quảng cáo. giao hàng hơi chậm nh...      0\n",
       "1      Mình nhận hàng ngày hôm qua, tiki giao hàng đú...      0\n",
       "2      Máy giặt quá tốt, chỉ có 5 tr được cái máy giặ...      0\n",
       "3      chất liệu vải tốt mát nói chung là chất lượng ...      0\n",
       "4       Tủ tốt giá tốt nhiều hơn so với các trung tâm...      0\n",
       "...                                                  ...    ...\n",
       "14301  dùng okee ko gây nóng máy nhưng chất của ốp om...      0\n",
       "14302  Rất tốt, rất đáng tiền, nằm rất êm, lúc mới mu...      0\n",
       "14303  giao đủ, đóng gói chắc chắn, giao hàng nhanh \\...      1\n",
       "14304  giao hỏa tốc rẻ và nhanh. Nhưng trước đó mình ...      0\n",
       "14305  Giao hàng nhanh, giá ổn, sản phẩm lắp sử dụng ...      0\n",
       "\n",
       "[14298 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slit data so that X_train is review and y_train is label\n",
    "X_train = data_train.iloc[:, 0:1]\n",
    "y_train = data_train.iloc[:, 1:2]\n",
    "\n",
    "X_dev = data_dev.iloc[:, 0:1]\n",
    "y_dev = data_dev.iloc[:, 1:2]\n",
    "\n",
    "X_test = data_test.iloc[:, 0:1]\n",
    "y_test = data_test.iloc[:, 1:2]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14301</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14302</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14303</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14304</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14305</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14298 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label\n",
       "0          0\n",
       "1          0\n",
       "2          0\n",
       "3          0\n",
       "4          0\n",
       "...      ...\n",
       "14301      0\n",
       "14302      0\n",
       "14303      1\n",
       "14304      0\n",
       "14305      0\n",
       "\n",
       "[14298 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dùng tốt, cắt lông mũi phù hợp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5 câu kinh điển mà một người vợ thông minh sẽ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hộp hơi móp chắc do vận chuyển ... Giao hàng l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Quần rất ổn, vải mát, mềm, giá rẻ, quá ưng.\\r\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nhìn khá ổn, chất lượng thì chưa nói trước điề...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1585</th>\n",
       "      <td>Tốt, dây chắc chắn, đầu mạng tốt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1586</th>\n",
       "      <td>hàng tốt, *** thử các loại nước khác nhau thì ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1587</th>\n",
       "      <td>great quality</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1588</th>\n",
       "      <td>Lấy 2 bộ 1 đen 1 trắng, bộ đen rất hài lòng, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1589</th>\n",
       "      <td>Sản phẩm hơi mỏng nhưng giá rẻ hơn các của dùn...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1590 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                comment\n",
       "0                        Dùng tốt, cắt lông mũi phù hợp\n",
       "1     5 câu kinh điển mà một người vợ thông minh sẽ ...\n",
       "2     Hộp hơi móp chắc do vận chuyển ... Giao hàng l...\n",
       "3     Quần rất ổn, vải mát, mềm, giá rẻ, quá ưng.\\r\\...\n",
       "4     Nhìn khá ổn, chất lượng thì chưa nói trước điề...\n",
       "...                                                 ...\n",
       "1585                   Tốt, dây chắc chắn, đầu mạng tốt\n",
       "1586  hàng tốt, *** thử các loại nước khác nhau thì ...\n",
       "1587                                      great quality\n",
       "1588  Lấy 2 bộ 1 đen 1 trắng, bộ đen rất hài lòng, b...\n",
       "1589  Sản phẩm hơi mỏng nhưng giá rẻ hơn các của dùn...\n",
       "\n",
       "[1590 rows x 1 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform X_train into narray (train_X) and simular\n",
    "train_X, train_y= pre_process_features(X_train['comment'], y_train['label'], tokenized=True, lowercased = True)\n",
    "dev_X, dev_y= pre_process_features(X_dev['comment'], y_dev['label'], tokenized=True, lowercased = True)\n",
    "test_X, test_y = pre_process_features(X_test['comment'], y_test['label'], tokenized=True, lowercased = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('dataset/internal-vocabulary.npy', train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14271,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14271,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DECLARE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "with open(EMBEDDING_PATH, encoding='utf8') as f:\n",
    "    for line in f:\n",
    "        values = line.rstrip().rsplit(' ')\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(lower=False, filters='!\"#$%&()*+,-./:;<=>?@[\\]^`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(TOKENIZER_PATH, 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_featues(X, y, tokenizer, is_one_hot_label=True, number_class1=2):\n",
    "#     X = tokenizer.texts_to_sequences(X)\n",
    "#     X = pad_sequences(X, maxlen=sequence_length)\n",
    "#     if is_one_hot_label: \n",
    "#         y = to_categorical(y, num_classes=number_class1)\n",
    "#     return X, y\n",
    "\n",
    "def make_featues(X, y, tokenizer, is_one_hot_label=False, number_class1=2): # my model just binary (non-spam or not spam)\n",
    "    X = tokenizer.texts_to_sequences(X)\n",
    "    X = pad_sequences(X, maxlen=sequence_length)\n",
    "    if is_one_hot_label: \n",
    "        y = to_categorical(y, num_classes=number_class1)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = 10000\n",
    "sequence_length = 100\n",
    "\n",
    "embedding_dim = 300\n",
    "batch_size = 256\n",
    "epochs = 40\n",
    "drop = 0.5\n",
    "\n",
    "filter_sizes = [2,3,5]\n",
    "num_filters = 32\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, embedding_dim))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i >= vocabulary_size:\n",
    "        continue\n",
    "\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_XX, train_yy = make_featues(train_X, train_y, tokenizer)\n",
    "dev_XX, dev_yy = make_featues(dev_X, dev_y, tokenizer)\n",
    "test_XX, test_yy = make_featues(test_X, test_y, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 1, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14271, 100)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_XX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0  268  141    3  710 6622   18\n",
      "  347   49  414  497   13   65   82 6623    4    7  711   37  119 2741\n",
      "  498  831]\n"
     ]
    }
   ],
   "source": [
    "print(train_XX[5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (14271, 100)\n",
      "<class 'numpy.ndarray'> (14271,)\n",
      "<class 'numpy.ndarray'> (1589, 100)\n",
      "<class 'numpy.ndarray'> (1589,)\n",
      "<class 'numpy.ndarray'> (3962, 100)\n",
      "<class 'numpy.ndarray'> (3962,)\n"
     ]
    }
   ],
   "source": [
    "print(type(train_XX), train_XX.shape)\n",
    "print(type(train_yy), train_yy.shape)\n",
    "print(type(dev_XX), dev_XX.shape)\n",
    "print(type(dev_yy), dev_yy.shape)\n",
    "print(type(test_XX), test_XX.shape)\n",
    "print(type(test_yy), test_yy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14271, 100)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_XX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNNs MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_max_pooling1d                 │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ global_max_pooling1d                 │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "│ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TextCNN\n",
    "# init layers\n",
    "textCNNModel = Sequential()\n",
    "\n",
    "# emmbed word vector\n",
    "textCNNModel.add(layers.Embedding(num_words, embedding_dim))\n",
    "\n",
    "# model\n",
    "textCNNModel.add(layers.Conv1D(128, 5, activation='relu'))\n",
    "textCNNModel.add(layers.GlobalMaxPooling1D())\n",
    "textCNNModel.add(layers.Dense(256, activation='relu'))\n",
    "\n",
    "# Output layer for binary classification\n",
    "textCNNModel.add(layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "# Compile the model\n",
    "textCNNModel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy']) \n",
    "\n",
    "textCNNModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "56/56 - 11s - 201ms/step - accuracy: 0.7732 - loss: 0.4978 - val_accuracy: 0.8414 - val_loss: 0.3941\n",
      "Epoch 2/40\n",
      "56/56 - 10s - 174ms/step - accuracy: 0.8733 - loss: 0.3144 - val_accuracy: 0.8383 - val_loss: 0.3771\n",
      "Epoch 3/40\n",
      "56/56 - 10s - 175ms/step - accuracy: 0.9263 - loss: 0.1926 - val_accuracy: 0.8062 - val_loss: 0.4550\n",
      "Epoch 4/40\n",
      "56/56 - 10s - 176ms/step - accuracy: 0.9649 - loss: 0.1049 - val_accuracy: 0.8433 - val_loss: 0.5607\n",
      "Epoch 5/40\n",
      "56/56 - 9s - 162ms/step - accuracy: 0.9815 - loss: 0.0548 - val_accuracy: 0.8320 - val_loss: 0.6120\n",
      "Epoch 6/40\n",
      "56/56 - 9s - 154ms/step - accuracy: 0.9879 - loss: 0.0365 - val_accuracy: 0.8357 - val_loss: 0.7431\n",
      "Epoch 7/40\n",
      "56/56 - 9s - 154ms/step - accuracy: 0.9910 - loss: 0.0256 - val_accuracy: 0.8376 - val_loss: 0.7425\n",
      "Epoch 8/40\n",
      "56/56 - 9s - 152ms/step - accuracy: 0.9938 - loss: 0.0181 - val_accuracy: 0.8402 - val_loss: 0.7888\n",
      "Epoch 9/40\n",
      "56/56 - 9s - 153ms/step - accuracy: 0.9946 - loss: 0.0162 - val_accuracy: 0.8326 - val_loss: 0.9063\n",
      "Epoch 10/40\n",
      "56/56 - 9s - 153ms/step - accuracy: 0.9947 - loss: 0.0164 - val_accuracy: 0.8339 - val_loss: 0.8913\n",
      "Epoch 11/40\n",
      "56/56 - 9s - 154ms/step - accuracy: 0.9954 - loss: 0.0148 - val_accuracy: 0.8320 - val_loss: 0.9216\n",
      "Epoch 12/40\n",
      "56/56 - 9s - 152ms/step - accuracy: 0.9957 - loss: 0.0132 - val_accuracy: 0.8357 - val_loss: 0.9120\n",
      "Epoch 13/40\n",
      "56/56 - 9s - 152ms/step - accuracy: 0.9968 - loss: 0.0107 - val_accuracy: 0.8383 - val_loss: 0.9576\n",
      "Epoch 14/40\n",
      "56/56 - 9s - 153ms/step - accuracy: 0.9957 - loss: 0.0108 - val_accuracy: 0.8213 - val_loss: 0.9511\n",
      "Epoch 15/40\n",
      "56/56 - 9s - 153ms/step - accuracy: 0.9963 - loss: 0.0112 - val_accuracy: 0.8345 - val_loss: 1.0042\n",
      "Epoch 16/40\n",
      "56/56 - 9s - 153ms/step - accuracy: 0.9971 - loss: 0.0090 - val_accuracy: 0.8326 - val_loss: 1.0958\n",
      "Epoch 17/40\n",
      "56/56 - 8s - 151ms/step - accuracy: 0.9970 - loss: 0.0102 - val_accuracy: 0.8339 - val_loss: 1.0163\n",
      "Epoch 18/40\n",
      "56/56 - 9s - 154ms/step - accuracy: 0.9972 - loss: 0.0085 - val_accuracy: 0.8370 - val_loss: 1.1489\n",
      "Epoch 19/40\n",
      "56/56 - 8s - 151ms/step - accuracy: 0.9972 - loss: 0.0085 - val_accuracy: 0.8332 - val_loss: 1.0472\n",
      "Epoch 20/40\n",
      "56/56 - 8s - 151ms/step - accuracy: 0.9973 - loss: 0.0077 - val_accuracy: 0.8301 - val_loss: 1.0607\n",
      "Epoch 21/40\n",
      "56/56 - 8s - 150ms/step - accuracy: 0.9976 - loss: 0.0072 - val_accuracy: 0.8357 - val_loss: 1.1720\n",
      "Epoch 22/40\n",
      "56/56 - 9s - 153ms/step - accuracy: 0.9976 - loss: 0.0073 - val_accuracy: 0.8307 - val_loss: 1.1425\n",
      "Epoch 23/40\n",
      "56/56 - 9s - 154ms/step - accuracy: 0.9970 - loss: 0.0080 - val_accuracy: 0.8282 - val_loss: 1.0887\n",
      "Epoch 24/40\n",
      "56/56 - 8s - 151ms/step - accuracy: 0.9967 - loss: 0.0089 - val_accuracy: 0.8320 - val_loss: 1.1811\n",
      "Epoch 25/40\n",
      "56/56 - 9s - 154ms/step - accuracy: 0.9973 - loss: 0.0086 - val_accuracy: 0.8383 - val_loss: 1.2028\n",
      "Epoch 26/40\n",
      "56/56 - 9s - 152ms/step - accuracy: 0.9966 - loss: 0.0083 - val_accuracy: 0.8282 - val_loss: 1.1679\n",
      "Epoch 27/40\n",
      "56/56 - 9s - 152ms/step - accuracy: 0.9975 - loss: 0.0075 - val_accuracy: 0.8150 - val_loss: 1.1266\n",
      "Epoch 28/40\n",
      "56/56 - 8s - 152ms/step - accuracy: 0.9973 - loss: 0.0079 - val_accuracy: 0.8244 - val_loss: 1.1271\n",
      "Epoch 29/40\n",
      "56/56 - 9s - 153ms/step - accuracy: 0.9971 - loss: 0.0088 - val_accuracy: 0.8288 - val_loss: 1.1409\n",
      "Epoch 30/40\n",
      "56/56 - 8s - 151ms/step - accuracy: 0.9976 - loss: 0.0074 - val_accuracy: 0.8295 - val_loss: 1.1924\n",
      "Epoch 31/40\n",
      "56/56 - 9s - 157ms/step - accuracy: 0.9975 - loss: 0.0070 - val_accuracy: 0.8301 - val_loss: 1.1806\n",
      "Epoch 32/40\n",
      "56/56 - 9s - 160ms/step - accuracy: 0.9973 - loss: 0.0082 - val_accuracy: 0.8225 - val_loss: 1.1915\n",
      "Epoch 33/40\n",
      "56/56 - 9s - 160ms/step - accuracy: 0.9975 - loss: 0.0080 - val_accuracy: 0.8320 - val_loss: 1.2703\n",
      "Epoch 34/40\n",
      "56/56 - 9s - 163ms/step - accuracy: 0.9971 - loss: 0.0086 - val_accuracy: 0.8320 - val_loss: 1.2217\n",
      "Epoch 35/40\n",
      "56/56 - 9s - 169ms/step - accuracy: 0.9959 - loss: 0.0117 - val_accuracy: 0.8301 - val_loss: 1.2666\n",
      "Epoch 36/40\n",
      "56/56 - 9s - 164ms/step - accuracy: 0.9942 - loss: 0.0175 - val_accuracy: 0.8414 - val_loss: 1.4630\n",
      "Epoch 37/40\n",
      "56/56 - 9s - 156ms/step - accuracy: 0.9849 - loss: 0.0439 - val_accuracy: 0.8332 - val_loss: 1.1100\n",
      "Epoch 38/40\n",
      "56/56 - 9s - 153ms/step - accuracy: 0.9899 - loss: 0.0272 - val_accuracy: 0.8313 - val_loss: 1.1033\n",
      "Epoch 39/40\n",
      "56/56 - 9s - 155ms/step - accuracy: 0.9961 - loss: 0.0113 - val_accuracy: 0.8439 - val_loss: 1.1974\n",
      "Epoch 40/40\n",
      "56/56 - 9s - 156ms/step - accuracy: 0.9971 - loss: 0.0086 - val_accuracy: 0.8288 - val_loss: 1.1666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f6fcd39890>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test for model accuracy\n",
    "textCNNModel.fit( train_XX, train_yy,\n",
    "    epochs=epochs,\n",
    "    verbose=2,\n",
    "    validation_data=(dev_XX, dev_yy),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8230 - loss: 1.2622\n",
      "LOSS: 1.2615290880203247\n",
      "Accuracy 0.818778395652771\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the TEST data\n",
    "loss, accuracy = textCNNModel.evaluate(test_XX, test_yy)\n",
    "print(f\"LOSS: {loss}\")\n",
    "print ('Accuracy '+ str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ spatial_dropout1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout1D</span>) │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ spatial_dropout1d (\u001b[38;5;33mSpatialDropout1D\u001b[0m) │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# LSTM\n",
    "# init layer\n",
    "lstmModel = Sequential()\n",
    "\n",
    "# emmbed word vectors\n",
    "lstmModel.add( layers.Embedding( num_words, embedding_dim) )\n",
    "lstmModel.add( layers.SpatialDropout1D(0.2) )\n",
    "\n",
    "# lstmModel.add( layers.LSTM( 100, return_sequences=False, dropout=0.5, recurrent_dropout=0.5 ) )\n",
    "lstmModel.add( layers.LSTM( 100, return_sequences=False ) )\n",
    "lstmModel.add( layers.Dense( 512, activation=\"relu\" ) )\n",
    "\n",
    "# Output layer for binary classification\n",
    "lstmModel.add( layers.Dense( 1, activation=\"sigmoid\" ) )\n",
    "\n",
    "# Compile the model\n",
    "lstmModel.compile( optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "\n",
    "lstmModel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "56/56 - 16s - 291ms/step - accuracy: 0.7747 - loss: 0.4962 - val_accuracy: 0.8326 - val_loss: 0.4142\n",
      "Epoch 2/40\n",
      "56/56 - 14s - 255ms/step - accuracy: 0.8619 - loss: 0.3291 - val_accuracy: 0.8420 - val_loss: 0.4044\n",
      "Epoch 3/40\n",
      "56/56 - 13s - 237ms/step - accuracy: 0.9024 - loss: 0.2459 - val_accuracy: 0.8357 - val_loss: 0.4398\n",
      "Epoch 4/40\n",
      "56/56 - 13s - 233ms/step - accuracy: 0.9280 - loss: 0.1832 - val_accuracy: 0.8307 - val_loss: 0.4756\n",
      "Epoch 5/40\n",
      "56/56 - 13s - 235ms/step - accuracy: 0.9474 - loss: 0.1410 - val_accuracy: 0.8206 - val_loss: 0.5278\n",
      "Epoch 6/40\n",
      "56/56 - 13s - 232ms/step - accuracy: 0.9558 - loss: 0.1164 - val_accuracy: 0.8263 - val_loss: 0.6002\n",
      "Epoch 7/40\n",
      "56/56 - 13s - 239ms/step - accuracy: 0.9634 - loss: 0.0979 - val_accuracy: 0.8244 - val_loss: 0.6350\n",
      "Epoch 8/40\n",
      "56/56 - 13s - 237ms/step - accuracy: 0.9660 - loss: 0.0886 - val_accuracy: 0.8206 - val_loss: 0.7044\n",
      "Epoch 9/40\n",
      "56/56 - 13s - 235ms/step - accuracy: 0.9692 - loss: 0.0775 - val_accuracy: 0.8188 - val_loss: 0.7860\n",
      "Epoch 10/40\n",
      "56/56 - 13s - 233ms/step - accuracy: 0.9741 - loss: 0.0671 - val_accuracy: 0.8150 - val_loss: 0.8008\n",
      "Epoch 11/40\n",
      "56/56 - 13s - 231ms/step - accuracy: 0.9758 - loss: 0.0629 - val_accuracy: 0.8181 - val_loss: 0.9962\n",
      "Epoch 12/40\n",
      "56/56 - 13s - 230ms/step - accuracy: 0.9796 - loss: 0.0533 - val_accuracy: 0.8143 - val_loss: 1.0418\n",
      "Epoch 13/40\n",
      "56/56 - 14s - 243ms/step - accuracy: 0.9800 - loss: 0.0540 - val_accuracy: 0.8250 - val_loss: 0.9981\n",
      "Epoch 14/40\n",
      "56/56 - 16s - 286ms/step - accuracy: 0.9800 - loss: 0.0521 - val_accuracy: 0.8118 - val_loss: 1.0435\n",
      "Epoch 15/40\n",
      "56/56 - 13s - 239ms/step - accuracy: 0.9837 - loss: 0.0443 - val_accuracy: 0.8093 - val_loss: 1.1485\n",
      "Epoch 16/40\n",
      "56/56 - 13s - 232ms/step - accuracy: 0.9843 - loss: 0.0414 - val_accuracy: 0.8150 - val_loss: 1.2232\n",
      "Epoch 17/40\n",
      "56/56 - 13s - 231ms/step - accuracy: 0.9847 - loss: 0.0409 - val_accuracy: 0.8081 - val_loss: 1.2631\n",
      "Epoch 18/40\n",
      "56/56 - 13s - 234ms/step - accuracy: 0.9878 - loss: 0.0354 - val_accuracy: 0.8068 - val_loss: 1.3273\n",
      "Epoch 19/40\n",
      "56/56 - 13s - 233ms/step - accuracy: 0.9859 - loss: 0.0381 - val_accuracy: 0.8055 - val_loss: 1.3452\n",
      "Epoch 20/40\n",
      "56/56 - 13s - 231ms/step - accuracy: 0.9866 - loss: 0.0370 - val_accuracy: 0.8087 - val_loss: 1.3667\n",
      "Epoch 21/40\n",
      "56/56 - 13s - 230ms/step - accuracy: 0.9866 - loss: 0.0369 - val_accuracy: 0.8175 - val_loss: 1.3364\n",
      "Epoch 22/40\n",
      "56/56 - 13s - 231ms/step - accuracy: 0.9882 - loss: 0.0322 - val_accuracy: 0.8049 - val_loss: 1.4319\n",
      "Epoch 23/40\n",
      "56/56 - 13s - 229ms/step - accuracy: 0.9878 - loss: 0.0339 - val_accuracy: 0.8062 - val_loss: 1.3211\n",
      "Epoch 24/40\n",
      "56/56 - 13s - 231ms/step - accuracy: 0.9900 - loss: 0.0296 - val_accuracy: 0.8125 - val_loss: 1.4427\n",
      "Epoch 25/40\n",
      "56/56 - 13s - 233ms/step - accuracy: 0.9912 - loss: 0.0250 - val_accuracy: 0.8137 - val_loss: 1.5767\n",
      "Epoch 26/40\n",
      "56/56 - 13s - 231ms/step - accuracy: 0.9915 - loss: 0.0237 - val_accuracy: 0.8062 - val_loss: 1.5732\n",
      "Epoch 27/40\n",
      "56/56 - 14s - 244ms/step - accuracy: 0.9910 - loss: 0.0251 - val_accuracy: 0.8024 - val_loss: 1.6420\n",
      "Epoch 28/40\n",
      "56/56 - 13s - 232ms/step - accuracy: 0.9906 - loss: 0.0237 - val_accuracy: 0.8175 - val_loss: 1.6126\n",
      "Epoch 29/40\n",
      "56/56 - 15s - 262ms/step - accuracy: 0.9930 - loss: 0.0218 - val_accuracy: 0.8137 - val_loss: 1.8652\n",
      "Epoch 30/40\n",
      "56/56 - 13s - 236ms/step - accuracy: 0.9908 - loss: 0.0262 - val_accuracy: 0.8150 - val_loss: 1.6814\n",
      "Epoch 31/40\n",
      "56/56 - 13s - 234ms/step - accuracy: 0.9922 - loss: 0.0230 - val_accuracy: 0.8156 - val_loss: 1.6971\n",
      "Epoch 32/40\n",
      "56/56 - 13s - 235ms/step - accuracy: 0.9929 - loss: 0.0198 - val_accuracy: 0.8150 - val_loss: 1.7826\n",
      "Epoch 33/40\n",
      "56/56 - 14s - 243ms/step - accuracy: 0.9917 - loss: 0.0236 - val_accuracy: 0.8099 - val_loss: 1.7677\n",
      "Epoch 34/40\n",
      "56/56 - 13s - 232ms/step - accuracy: 0.9916 - loss: 0.0227 - val_accuracy: 0.8162 - val_loss: 1.8179\n",
      "Epoch 35/40\n",
      "56/56 - 13s - 235ms/step - accuracy: 0.9915 - loss: 0.0251 - val_accuracy: 0.8030 - val_loss: 1.6777\n",
      "Epoch 36/40\n",
      "56/56 - 13s - 231ms/step - accuracy: 0.9925 - loss: 0.0226 - val_accuracy: 0.8093 - val_loss: 1.6762\n",
      "Epoch 37/40\n",
      "56/56 - 13s - 235ms/step - accuracy: 0.9939 - loss: 0.0175 - val_accuracy: 0.8043 - val_loss: 1.7931\n",
      "Epoch 38/40\n",
      "56/56 - 13s - 232ms/step - accuracy: 0.9941 - loss: 0.0164 - val_accuracy: 0.8162 - val_loss: 1.9223\n",
      "Epoch 39/40\n",
      "56/56 - 13s - 231ms/step - accuracy: 0.9943 - loss: 0.0157 - val_accuracy: 0.8062 - val_loss: 1.9399\n",
      "Epoch 40/40\n",
      "56/56 - 13s - 233ms/step - accuracy: 0.9948 - loss: 0.0146 - val_accuracy: 0.7967 - val_loss: 1.9332\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f74ccf9250>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# utils.plot_model(lstmModel)\n",
    "lstmModel.fit( train_XX, train_yy,\n",
    "    epochs=epochs,\n",
    "    verbose=2,\n",
    "    validation_data=(dev_XX, dev_yy),\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m124/124\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.8075 - loss: 1.7562\n",
      "LOSS: 1.8377150297164917\n",
      "Accuracy 0.8028773069381714\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the DEV data\n",
    "loss, accuracy = lstmModel.evaluate(test_XX, test_yy)\n",
    "print(f\"LOSS: {loss}\")\n",
    "print ('Accuracy '+ str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SAVE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "CNNs = os.path.join(MODEL_DIR, 'CNNs.keras')  \n",
    "LSTM = os.path.join(MODEL_DIR, 'LSTM.keras')\n",
    "\n",
    "textCNNModel.save(CNNs)\n",
    "lstmModel.save(LSTM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
